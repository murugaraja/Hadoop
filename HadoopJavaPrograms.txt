Hadoop Using Java Programs :-  (Reference book:  Hadoop The Definitive Guide (3rd Edition) - Tom White
==============================
Lets assume all java sources stored in "/home/hadoop/ ".
IP address: 192.168.81.149
Port no   : 11110     (According to core-site.xml ;  fs.default.name=>hdfs://192.168.81.149:11110)

$ HADOOP_PERFIX=/usr/local/hadoop/     (Hadoop home location)
$ JAVA_HOME=/usr/lib/jvm/openjdk-7-java-i386    (Java home location)

To upload a file to HDFS:
Hint: $ hadoop fs -copyFromLocal  /home/hadoop/temp.txt   /naveen/data/temp.txt


Read from a file:
=================
$ vi URLCat.java      (to enable insert mode press "I" , once edited   press Esc key and  :wq )   
Step 1: create a java file as "URLCat.java"
-------------------------------------------

package com.naveen.hadoop.fs;

import java.io.InputStream;
import java.net.URL;
import org.apache.hadoop.fs.FsUrlStreamHandlerFactory;
import org.apache.hadoop.io.IOUtils;
public class URLCat {
	static{
		URL.setURLStreamHandlerFactory(new FsUrlStreamHandlerFactory());
	}
	public static void main(String[] args) {
		String location="hdfs://192.168.81.149:11110/naveen/data/temp.txt";
		if(args.length>0) location=args[0];
		InputStream in=null;
		try{
			System.out.println("\n test 1 - Try block started  ");
			in=new URL(location).openStream();//("hdfs://192.168.81.149:11110/naveen/data/temp.txt");
//			url.setURLStreamHandlerFactory(new FsUrlStreamHandlerFactory());  // to recognize "hdfs://"
//			in=url.openStream();
			IOUtils.copyBytes(in, System.out, 4096 ,false);

			/*
			 * $ hadoop URLCat hdfs://localhost/user/tom/quangle.txt
			 */

		}catch(Exception ex){

			System.out.println("test 2 - catch block ");
			ex.printStackTrace();
		}
		finally{
			System.out.println("test 3 - finally block ");
			IOUtils.closeStream(in);
		}
	}

}


Step 2: To Compile:
-------------------
$ export CLASSPATH=$CLASSPATH:/usr/local/hadoop/hadoop-core-1.2.0.jar
$ javac -d  /home/hadoop/  *.java  
   [or]
$ javac -d  /home/hadoop/  URLCat.java
   [or]
$ javac -d  .  URLCat.java

Step 3: To Execute:
-------------------
 [ ** important before execution we need to set Hadoop_classpath **]
$ export HADOOP_CLASSPATH=/home/hadoop/com/naveen/hadoop/fs/        (in which java classes available)

$ hadoop com.naveen.hadoop.fs.URLCat
   [ or ]
$ hadoop com.naveen.hadoop.fs.URLCat hdfs://192.168.81.149:11110/naveen/data/temp.txt





Programs:
==========
To Read from file:
--------------------
package com.naveen.hadoop.fs;
import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.fs.FileSystem;
import org.apache.hadoop.io.IOUtils;
import java.net.URI;
import java.io.InputStream;
public class FileSystemCat{

	public static void main(String args[]){
		String uri="hdfs://192.168.81.149:11110/naveen/data/resume.txt";
		if(args.length !=0) uri=args[0];
		Configuration config=new Configuration();
		FileSystem fs=null;
		InputStream in=null;
		try{
			fs=FileSystem.get(URI.create(uri),config);
			in=fs.open(new Path(uri));
			IOUtils.copyBytes(in,System.out,4096,false);
		}catch(Exception ex){
			System.out.println("Cool : "+ ex);
		}finally{
//			IOUtils.closeStream(in);
		}


	}

}



Two times display the content using "seek"
----------------------------------------
package com.naveen.hadoop.fs;
import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.fs.FileSystem;
import org.apache.hadoop.io.IOUtils;
import org.apache.hadoop.fs.FSDataInputStream;
import java.net.URI;
import java.io.InputStream;
public class FileSystemDoubleCatUsingSeek{

	public static void main(String args[]){
		String uri="hdfs://192.168.81.149:11110/naveen/data/resume.txt";
		if(args.length !=0) uri=args[0];
		Configuration config=new Configuration();
		FileSystem fs=null;
		FSDataInputStream in=null;
		try{
			fs=FileSystem.get(URI.create(uri),config);
			in=fs.open(new Path(uri));
			IOUtils.copyBytes(in,System.out,4096,false);
			System.out.println("\n\n*****************Copy****************\n\n");
			in.seek(0L); // go back to start of the file 
			IOUtils.copyBytes(in,System.out,8192,false);
		}catch(Exception ex){
			System.out.println("Cool : "+ ex);
		}finally{
//			IOUtils.closeStream(in);
		}


	}

}



Copy from a file to another file:
---------------------------------
package com.naveen.hadoop.fs;
import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.FileSystem;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.io.IOUtils;
import org.apache.hadoop.util.Progressable;
import java.io.*;
import java.net.URI;


public class FileCopyWithProgress{

	public static void main(String args[]){

		String localSrc="/home/hadoop/resume.txt";
		String destSrc="hdfs://192.168.81.149:11110/naveen/data/dummyres.txt";
		if(args.length > 0){
			localSrc=args[0];
			destSrc=args[1];
		} 
		FileSystem fs=null;
		InputStream in=null;
		Configuration conf=new Configuration();
//		fs=FileSystem.get(URI.create(destSrc) , conf);
		try{
			in=new BufferedInputStream(new FileInputStream(localSrc));

			fs=FileSystem.get(URI.create(destSrc), conf);
			OutputStream os=fs.create(new Path(destSrc), new Progressable(){
				public void progress(){
					System.out.println("Cool ... it's going on...");
				}
			}
			);
			IOUtils.copyBytes(in,os,4096,true);

			System.out.println("Done");
		}
		catch(Exception e){
			System.out.println(e);
		}




	}

}

